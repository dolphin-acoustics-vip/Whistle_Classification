{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning_Dolphin_Acoustics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook uses tranfer learning to classify spectrogram data on dolphin whistles. Much of the code used here was adpapted from https://keras.io/guides/transfer_learning/.\n",
        "\n",
        "Credit for parts of the code dealing with the `ImageDataGenerator` is given to Josh Wheeler and Gemma Ruseva (https://github.com/JoshWheeler08/DolphinAcoustics-Classifier/blob/main/vip_dolphin.ipynb)\n",
        "\n",
        "The code seeks to make a model which can distinguish among Common, Melon Head, and Bottlenose dolphin species."
      ],
      "metadata": {
        "id": "wNpTm6ROgBl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDOl4Q4DGTbT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# TODO: Ensure data is standardized properly before training (look especially at rescaling code)\n",
        "# TODO: fine tune on different spectrogram data used to fit model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive so data can be accessed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # '/content' is the current working directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYtXIJi-NK9v",
        "outputId": "8d64f204-8ec6-4fee-cf04-f43b4e9dd7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Base Model and Adding Extra Layers\n",
        "\n",
        "Here we load the Xception base model for transfer learning.This is a fairly complex CNN-based model. More can be read about it here: https://arxiv.org/abs/1610.02357.\n",
        "\n",
        "The base model is \"frozen\" so that its hyperparameters are not drastically changed by subsequent training. \n",
        "\n",
        "We then add two new layers for training on the spectrogram data.\n",
        "\n",
        "A list of several alternatives to the Xception base model can be found here: https://keras.io/api/applications/#available-models. "
      ],
      "metadata": {
        "id": "44Aew7Y5e0qd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input shape set to that used with the dolphins spectrogram data\n",
        "image_shape = (413, 202, 3)\n",
        "\n",
        "base_model = keras.applications.Xception(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=image_shape, \n",
        "    include_top=False,\n",
        ")  # Do not include the ImageNet classifier at the top.\n",
        "\n",
        "# Freeze the base_model\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create new model on top\n",
        "inputs = keras.Input(shape=image_shape)  # (150, 150, 3)\n",
        "x = keras.Sequential()(inputs)#data_augmentation(inputs)\n",
        "\n",
        "# Pre-trained Xception weights requires that input be scaled\n",
        "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
        "# outputs: `(inputs * scale) + offset`\n",
        "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
        "x = scale_layer(x)\n",
        "\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "\n",
        "number_of_outputs = 3 # Here, the number of outputs is set to three since we are working \n",
        "                      # on a three-category multi-classification problem.\n",
        "outputs = keras.layers.Dense(number_of_outputs)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujt1oXivG1W9",
        "outputId": "e4852631-5875-47e8-de67-986fd38d1610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n",
            "83697664/83683744 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 413, 202, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     multiple                  0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 413, 202, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 13, 7, 2048)       20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 6147      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,867,627\n",
            "Trainable params: 6,147\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Training, Test and Validation Data\n",
        "\n",
        "The spectrogram image data are now loaded."
      ],
      "metadata": {
        "id": "4z-YiiS1iMO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code section adapted from https://github.com/JoshWheeler08/DolphinAcoustics-Classifier/blob/main/vip_dolphin.ipynb\n",
        "\n",
        "IMAGE_SHAPE = (413, 202)\n",
        "directory_name = \"/content/drive/MyDrive/Dolphin_Acoustics_VIP/model_test_train/\"\n",
        "\n",
        "TEST_DATA_DIR = directory_name + \"test\"\n",
        "TRAINING_DATA_DIR = directory_name + \"train\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=.20\n",
        ") #https://stackoverflow.com/questions/42443936/keras-split-train-test-set-when-using-imagedatagenerator\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "                    rescale=1./255\n",
        "                ).flow_from_directory(\n",
        "                      TEST_DATA_DIR,\n",
        "                      shuffle=True,\n",
        "                      batch_size = 50,\n",
        "                      target_size=IMAGE_SHAPE\n",
        "                      )\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR,\n",
        "    subset=\"validation\",\n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE\n",
        ")\n",
        "                \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z810mkC7La07",
        "outputId": "4eb330a6-d0b9-4ce0-badb-935a53855a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 600 images belonging to 3 classes.\n",
            "Found 480 images belonging to 3 classes.\n",
            "Found 1920 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting the Model to the Spectrogram image data.\n",
        "\n",
        "We now compile and fit the model. The new classification layers are trained, while the base model's hyperparameters remain unchanged."
      ],
      "metadata": {
        "id": "7HWnD4YCigQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()]\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "#image_data, image_labels = test_generator.next()\n",
        "model.fit(test_generator, epochs=epochs, validation_data=validation_generator)\n",
        "model.save(directory_name + \"transfer_learning_classifier.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9jP2AUsG2tJ",
        "outputId": "063b3471-c7bd-47be-dcba-79aceb46f3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 237s 19s/step - loss: 1.1059 - categorical_accuracy: 0.3333 - val_loss: 1.0966 - val_categorical_accuracy: 0.3333\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.1098 - categorical_accuracy: 0.3067 - val_loss: 1.0966 - val_categorical_accuracy: 0.3333\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.0970 - categorical_accuracy: 0.3717 - val_loss: 1.0936 - val_categorical_accuracy: 0.5646\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.1011 - categorical_accuracy: 0.3383 - val_loss: 1.0936 - val_categorical_accuracy: 0.3333\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.0910 - categorical_accuracy: 0.3900 - val_loss: 1.0908 - val_categorical_accuracy: 0.5437\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.0953 - categorical_accuracy: 0.3750 - val_loss: 1.0894 - val_categorical_accuracy: 0.5646\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.0955 - categorical_accuracy: 0.3583 - val_loss: 1.0888 - val_categorical_accuracy: 0.4396\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.0935 - categorical_accuracy: 0.3767 - val_loss: 1.0876 - val_categorical_accuracy: 0.3333\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.0966 - categorical_accuracy: 0.3633 - val_loss: 1.0855 - val_categorical_accuracy: 0.5437\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 21s 2s/step - loss: 1.0886 - categorical_accuracy: 0.3917 - val_loss: 1.0841 - val_categorical_accuracy: 0.5333\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dolphin_Acoustics_VIP/model_test_train/transfer_learning_classifier.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning the Model\n",
        "\n",
        "Now that we have trained our own classification layers on top of the Xception base model, we can train all layers of the model now by setting `base_model.trainable = True` (i.e. \"unfreezing\" the base model) and setting a very low learning rate. A low learning rate is used to prevent destroying the pre-trained its useful pre-trained features.\n",
        "\n",
        "Doing this would ideally provide an extra boost to the model's performance, but it can lead to overfitting."
      ],
      "metadata": {
        "id": "3eBprpC3lUV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
        "# since we passed `training=False` when calling it. This means that\n",
        "# the batchnorm layers will not update their batch statistics.\n",
        "# This prevents the batchnorm layers from undoing all the training\n",
        "# we've done so far.\n",
        "base_model.trainable = True\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.CategoricalAccuracy()]\n",
        ")\n",
        "\n",
        "epochs = 5\n",
        "model.fit(train_generator, epochs=epochs, validation_data=validation_generator)\n",
        "model.save(directory_name + \"transfer_learning_classifier_fine_tuned.model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3tzX1iLdi3j",
        "outputId": "09dfddbd-66e9-4ae5-e8fd-a9318a553399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 413, 202, 3)]     0         \n",
            "                                                                 \n",
            " sequential (Sequential)     multiple                  0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 413, 202, 3)       0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 13, 7, 2048)       20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 3)                 6147      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,867,627\n",
            "Trainable params: 20,813,099\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "60/60 [==============================] - 521s 8s/step - loss: 1.0943 - categorical_accuracy: 0.3760 - val_loss: 1.0931 - val_categorical_accuracy: 0.3396\n",
            "Epoch 2/5\n",
            "60/60 [==============================] - 187s 3s/step - loss: 1.0720 - categorical_accuracy: 0.4198 - val_loss: 1.0711 - val_categorical_accuracy: 0.3625\n",
            "Epoch 3/5\n",
            "60/60 [==============================] - 187s 3s/step - loss: 0.9840 - categorical_accuracy: 0.5068 - val_loss: 0.9809 - val_categorical_accuracy: 0.5625\n",
            "Epoch 4/5\n",
            "60/60 [==============================] - 188s 3s/step - loss: 0.9639 - categorical_accuracy: 0.5172 - val_loss: 0.8776 - val_categorical_accuracy: 0.6562\n",
            "Epoch 5/5\n",
            "60/60 [==============================] - 187s 3s/step - loss: 0.9303 - categorical_accuracy: 0.5234 - val_loss: 0.8938 - val_categorical_accuracy: 0.5729\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Dolphin_Acoustics_VIP/model_test_train/transfer_learning_classifier_fine_tuned.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code section adapted from https://github.com/JoshWheeler08/DolphinAcoustics-Classifier/blob/main/vip_dolphin.ipynb\n",
        "\n",
        "classes = dict((v,k) for k,v in (train_generator.class_indices).items())\n",
        "\n",
        "test_generator.reset()\n",
        "test_labels = test_generator.classes\n",
        "array_of_class_names = np.array(list(classes.values()))\n",
        "y_hat = model.predict(test_generator)\n",
        "print(classification_report(test_labels,y_hat.argmax(axis=1), target_names=array_of_class_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfTGJ0L8RXht",
        "outputId": "a102030a-8d25-4d46-83f4-560772f4ab66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "  bottlenose       0.32      0.14      0.20       200\n",
            "      common       0.37      0.33      0.34       200\n",
            "melon-headed       0.34      0.57      0.43       200\n",
            "\n",
            "    accuracy                           0.35       600\n",
            "   macro avg       0.34      0.35      0.32       600\n",
            "weighted avg       0.34      0.35      0.32       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code section adapted from https://github.com/JoshWheeler08/DolphinAcoustics-Classifier/blob/main/vip_dolphin.ipynb\n",
        "\n",
        "test_generator.reset()\n",
        "test_loss, test_acc = model.evaluate(test_generator, verbose=2) # TODO: Check the return values for this\n",
        "\n",
        "# SUMMARY STATISTICS\n",
        "print(\"----- Evaluation Summary statistics -----\")\n",
        "print(\"Test accuracy = \", test_acc)\n",
        "print(\"Test loss = \", test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_aezGWqXFPY",
        "outputId": "6a23d019-6e53-4069-900b-8b930ae66edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/12 - 12s - loss: 0.8664 - categorical_accuracy: 0.6383 - 12s/epoch - 973ms/step\n",
            "----- Evaluation Summary statistics -----\n",
            "Test accuracy =  0.6383333206176758\n",
            "Test loss =  0.8664476275444031\n"
          ]
        }
      ]
    }
  ]
}